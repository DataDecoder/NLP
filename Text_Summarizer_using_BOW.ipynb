{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, PorterStemmer, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Tokenize the Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"D:/ISDC Work/Python Codes/Text_Mining_SJCC/text_data/new_t1.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'story', 'takes', 'place', 'in', 'its', 'own', 'universe', '.', 'It', 'has', 'no', 'connection', 'to', 'any', 'of', 'the', 'DC', 'films', 'that', 'have', 'come', 'before', 'it', '.', 'We', 'see', 'it', 'as', 'a', 'classic', 'Warner', 'Bros.', 'movie', '.', 'Gritty', ',', 'intimate', 'and', 'oddly', 'funny', ',', 'the', 'characters', 'live', 'in', 'the', 'real', 'world', 'and', 'the', 'stakes', 'are', 'personal', '.', 'Although', 'it', 'is', 'never', 'mentioned', 'in', 'the', 'film', ',', 'this', 'story', 'takes', 'place', 'in', 'the', 'past', '.', 'Let', \"'s\", 'call', 'it', '1981', '.', 'It', \"'s\", 'a', 'troubled', 'time', '.', 'The', 'crime', 'rate', 'in', 'Gotham', 'is', 'at', 'record', 'highs', '.', 'A', 'garbage', 'strike', 'has', 'crippled', 'the', 'city', 'for', 'the', 'past', 'six', 'weeks', '.', 'And', 'the', 'divide', 'between', 'the', '``', 'haves', \"''\", 'and', 'the', '``', 'have-', 'nots', \"''\", 'is', 'palpable', '.', 'Dreams', 'are', 'beyond', 'reach', ',', 'slipping', 'into', 'delusions', '.', 'OVER', 'BLACK', ':', 'HEAR', 'LAUGHTER', '.', 'The', 'sound', 'of', 'a', 'man', 'totally', 'cracking', 'up', '.', 'FADE', 'IN', ':', '1', 'INT', '.', 'DEPT', '.', 'OF', 'HEALTH', ',', 'OFFICE', '-', 'MORNING', '1', 'CLOSE', 'ON', 'JOKER', '(', '30', \"'s\", ')', ',', 'tears', 'in', 'his', 'eyes', 'from', 'laughing', 'so', 'hard', '.', 'He', \"'s\", 'trying', 'to', 'get', 'it', 'under', 'control', '.', 'His', 'greasy', ',', 'black', 'hair', 'is', 'matted', 'down', '.', 'He', \"'s\", 'wearing', 'an', 'old', ',', 'faded', 'red', 'hooded', 'zip-up', 'sweatshirt', ',', 'a', 'threadbare', 'gray', 'scarf', ',', 'thin', 'from', 'years', 'of', 'use', ',', 'hangs', 'loosely', 'around', 'his', 'neck', '.', 'WE', 'NOTICE', 'TWO', 'FADED', 'OLD', 'SCARS', 'cut', 'at', 'the', 'corners', 'of', 'his', 'mouth', '.', 'Almost', 'forming', 'a', 'smile', '.', 'He', \"'s\", 'sitting', 'across', 'from', 'an', 'overworked', 'SOCIAL', 'WORKER', '(', '50', \"'s\", ')', ',', 'African', 'American', '.', 'Her', 'office', 'is', 'cramped', 'and', 'run-down', 'in', 'a', 'cramped', 'and', 'run-down', 'building', '.', 'Stacks', 'of', 'folders', 'piled', 'high', 'in', 'front', 'of', 'her', '.', 'She', 'just', 'sits', 'behind', 'her', 'desk', ',', 'waiting', 'for', 'his', 'laughing', 'fit', 'to', 'end', ',', 'she', \"'s\", 'been', 'through', 'this', 'before', '.', 'Finally', 'it', 'subsides', '.', 'Joker', 'takes', 'a', 'deep', 'breath', ',', 'pauses', 'to', 'see', 'if', 'it', \"'s\", 'over', '.', 'Beat', '.', 'JOKER', '--', 'is', 'it', 'just', 'me', ',', 'or', 'is', 'it', 'getting', 'crazier', 'out', 'there', '?', 'Despite', 'the', 'laughter', ',', 'there', \"'s\", 'real', 'pain', 'in', 'his', 'eyes', '.', 'Something', 'broken', 'in', 'him', '.', 'Looks', 'like', 'he', 'has', \"n't\", 'slept', 'in', 'days', '.', 'SOCIAL', 'WORKER', 'It', \"'s\", 'certainly', 'tense', '.', 'People', 'are', 'upset', ',', 'they', \"'re\", 'struggling', '.', 'Looking', 'for', 'work', '.', 'The', 'garbage', 'strike', 'seems', 'like', 'it', \"'s\", 'been', 'going', 'on', 'forever', '.', 'These', 'are', 'tough', 'times', '.', '(', 'then', ')', 'How', \"'bout\", 'you', '.', 'How', \"'s\", 'the', 'job', '?', 'Still', 'enjoying', 'it', '?', 'JOKER', 'Yeah', ',', 'I', 'mean', ',', 'it', \"'s\", 'different', 'each', 'day', ',', 'so', 'I', 'really', 'like', 'that', '.', 'I', \"don't\", 'think', 'I', 'could', 'ever', 'work', 'in', 'an', 'office', '.', 'Behind', 'a', 'desk', '.', '(', 'MORE', ')', '2', '.', 'JOKER', '(', 'CONT', \"'D\", ')', '(', 'beat', ')', 'No', 'offense', '.', 'She', 'smiles', '.', 'Writes', 'something', 'down', '.', 'Looks', 'at', 'the', 'clock', ',', \"she's\", 'running', 'late', 'for', 'her', 'next', 'appointment', '.', 'SOCIAL', 'WORKER', 'Have', 'you', 'been', 'keeping', 'up', 'with', 'your', 'journal', '?', 'JOKER', 'Everyday', '.', 'SOCIAL', 'WORKER', 'Great', '.', 'Did', 'you', 'bring', 'it', 'with', 'you', '?', 'Beat', '.', 'JOKER', '(', 'dodging', 'the', 'subject', ')', 'I', \"'m\", 'sorry', '.', 'Did', 'I', 'bring', 'what', '?', 'SOCIAL', 'WORKER', '(', 'impatient', ';', 'she', \"doesn't\", 'have', 'time', 'for', 'this', ')', 'Arthur', ',', 'last', 'time', 'I', 'asked', 'you', 'to', 'bring', 'your', 'journal', 'with', 'you', '.', 'For', 'these', 'appointments', '.', 'Do', 'you', 'have', 'it', '?', 'JOKER', 'Yes', \"ma'am\", '.', 'Beat', '.', 'SOCIAL', 'WORKER', 'Can', 'I', 'see', 'it', '?', 'He', 'reluctantly', 'reaches', 'into', 'his', 'bag', '.', 'Pulls', 'out', 'a', 'weathered', 'notebook', '.', 'Slides', 'it', 'across', 'to', 'her', '--', 'JOKER', 'I', \"'ve\", 'been', 'using', 'it', 'as', 'a', 'journal', ',', 'but', 'also', 'a', 'joke', 'diary', '.', 'Funny', 'thoughts', 'or', ',', 'or', 'observations', '--', 'Did', 'I', 'tell', 'you', 'I', \"'m\", 'pursuing', 'a', 'career', 'in', 'stand-up', 'comedy', '?', 'She', \"'s\", 'half-listening', 'as', 'she', 'flips', 'through', 'his', 'journal', '.', 'SOCIAL', 'WORKER', 'No', '.', 'You', 'did', \"n't\", '.', 'JOKER', 'I', 'think', 'I', 'did', '.', '3', '.', 'She', 'does', \"n't\", 'respond', ',', 'keeps', 'flipping', 'through', 'his', 'journal', '--', 'SOCIAL', 'WORKER', 'Oh', 'yeah', '.', 'Because', 'of', 'what', 'your', 'mother', 'said', ',', '--', 'about', 'your', 'purpose', '.', '``', 'To', 'bring', 'laughter', 'and', 'joy', 'to', 'the', 'world', ',', \"''\", 'right', '?', 'JOKER', 'Right', '.', 'ANGLE', 'ON', 'JOURNAL', ',', 'pages', 'and', 'pages', 'of', 'notes', ',', 'all', 'in', 'neat', ',', 'angry-looking', 'handwriting', '.', 'Also', ',', 'cut', 'out', 'photos', 'from', 'hardcore', 'pornographic', 'magazines', 'and', 'some', 'crude', 'handmade', 'drawings', '.', 'A', 'flash', 'of', 'anger', 'crosses', 'Joker', \"'s\", 'face', '.', 'We', 'see', 'him', 'picking', 'at', 'his', 'right', 'eyebrow', ',', 'almost', 'obsessively', '.', 'Trying', 'to', 'stay', 'calm', '.', 'His', 'eyebrow', 'is', 'actually', 'half-gone', '.', 'Something', 'he', 'does', 'a', 'lot', '.', 'JOKER', 'I', 'did', \"n't\", 'realize', 'you', 'wanted', 'to', 'read', 'it', '.', 'The', 'social', 'worker', 'gives', 'him', 'a', 'look', ',', 'then', 'reads', 'something', 'in', 'the', 'pages', 'that', 'gives', 'her', 'pause', '.', 'SOCIAL', 'WORKER', '(', 'reading', 'out', 'loud', ')', '``', 'I', 'just', 'hope', 'my', 'death', 'makes', 'more', 'sense', 'than', 'my', 'life', '.', \"''\", 'She', 'looks', 'up', 'at', 'Joker', '.', 'He', 'just', 'stares', 'back', '.', 'Lets', 'it', 'hang', 'out', 'there', 'for', 'a', 'beat', '.', 'Then', 'he', 'laughs', 'a', 'little', ',', 'even', 'though', 'he', 'does', \"n't\", 'think', \"it's\", 'funny', '--', 'JOKER', 'Yeah', '.', 'I', 'mean', ',', 'that', \"'s\", 'just', '--', 'SOCIAL', 'WORKER', 'Does', 'my', 'reading', 'it', 'upset', 'you', '?', 'He', 'leans', 'in', '.', 'JOKER', 'No', '.', 'I', 'just', ',', '--', 'some', 'of', \"it's\", 'personal', '.', 'You', 'know', '?', 'SOCIAL', 'WORKER', 'I', 'understand', '.', 'I', 'just', 'want', 'to', 'make', 'sure', 'you', \"'re\", 'keeping', 'up', 'with', 'it', '.', 'She', 'slides', 'his', 'journal', 'back', 'to', 'him', '.', 'He', 'holds', 'it', 'in', 'his', 'lap', '.', '4', '.', 'SOCIAL', 'WORKER', 'What', 'about', 'your', 'mom', '?', 'How', \"'s\", 'she', 'feeling', '?', 'JOKER', 'She', 'has', 'good', 'days', '.', 'But', 'mostly', 'bad', '.', 'It', \"'s\", 'been', 'a', 'big', 'help', 'having', 'me', 'there', '.', 'She', 'really', 'needs', 'me', '.', 'SOCIAL', 'WORKER', 'Seems', 'like', 'she', \"'s\", 'been', 'sick', 'a', 'lot', 'since', 'you', 'got', 'home', '.', 'JOKER', '(', 'nods', ')', 'Yeah', ',', 'it', \"'s\", 'good', 'I', \"'m\", 'there', '.', 'When', 'I', 'was', 'in', 'the', 'hospital', ',', 'after', 'my', 'last', 'episode', '--', 'she', 'was', 'having', 'trouble', 'getting', 'over', 'there', 'to', 'visit', '.', 'She', 'looks', 'back', 'up', 'at', 'the', 'clock', ',', 'she', 'needs', 'to', 'get', 'to', 'her', 'next', 'appointment', '.', 'SOCIAL', 'WORKER', 'All', 'right', '.', 'So', ',', 'I', \"'ll\", 'see', 'you', 'again', ',', 'two', 'weeks', 'from', 'today', '?', 'He', 'nods', '.', 'But', 'keeps', 'sitting', 'there', 'for', 'a', 'moment', '.', 'She', 'stands', 'up', ',', 'trying', 'to', 'signal', 'it', \"'s\", 'time', 'for', 'him', 'to', 'leave', '--', 'SOCIAL', 'WORKER', 'Is', 'there', 'something', 'else', 'I', 'can', 'help', 'you', 'with', ',', 'Arthur', '?', 'My', 'next', 'appointment', 'is', 'waiting', '.', 'He', 'just', 'keeps', 'sitting', 'there', '.', 'JOKER', 'Yeah', ',', 'I', 'was', 'wondering', 'if', 'you', 'could', 'ask', 'the', 'doctor', 'to', 'increase', 'the', 'dosage', 'on', 'my', 'medications', '?', 'Nothing', 'seems', 'to', 'make', 'a', 'difference', '.', 'SOCIAL', 'WORKER', '(', 'looking', 'over', 'his', 'record', ')', 'Do', 'you', 'know', 'which', 'ones', 'you', \"'d\", 'like', 'increased', '?', 'Shakes', 'his', 'head', ',', 'no', '.', 'SOCIAL', 'WORKER', 'Have', 'you', 'been', 'sleeping', '?', '5', '.', 'JOKER', '(', 'lying', ')', 'Some', '.', 'She', 'glances', 'at', 'his', 'file', 'again', '.', 'SOCIAL', 'WORKER', 'Arthur', ',', 'you', \"'re\", 'on', 'seven', 'different', 'medications', '.', 'Surely', 'they', 'must', 'be', 'doing', 'something', '.', 'He', 'finally', 'stands', 'up', '.', 'Zips', 'up', 'his', 'faded', 'red', 'sweatshirt', '.', 'Looks', 'at', 'her', '--', 'JOKER', 'I', 'just', 'do', \"n't\", 'wan', 'na', 'feel', 'so', 'bad', 'anymore', '.']\n"
     ]
    }
   ],
   "source": [
    "sentences = word_tokenize(text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1227"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_documents = len(sentences)\n",
    "total_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Frequency Matrix for the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    sw = set(stopwords.words('english'))\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    for sent in sentences: \n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            word = ps.stem(word)\n",
    "            if word in sw:\n",
    "                continue\n",
    "            if word in freq_table:\n",
    "                freq_table[word] = freq_table[word] + 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "        frequency_matrix[sent[:15]] = freq_table\n",
    "    return frequency_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Term-Frequency Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "        count_words_in_sent = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sent\n",
    "        tf_matrix[sent] = tf_table\n",
    "    return tf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a table for document per words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_document_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] = word_per_doc_table[word] + 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "    return word_per_doc_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual IDF Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "        idf_matrix[sent] = idf_table\n",
    "    return idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "        tf_idf_table = {}\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(), f_table2.items()):\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "        tf_idf_matrix[sent1] = tf_idf_table\n",
    "    return tf_idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighing the words in a sentence - Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_sentences(tf_idf_matrix) -> dict: \n",
    "    sentence_val = {}\n",
    "    for sent, f_table in tf_idf_matrix.items():\n",
    "        total_score_per_sentence = 0\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, score in f_table.items():\n",
    "            total_score_per_sentence = total_score_per_sentence + score\n",
    "        if count_words_in_sentence > 0:\n",
    "            sentence_val[sent] = total_score_per_sentence / count_words_in_sentence\n",
    "    return sentence_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average sentence score - Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_average_score(sentence_val) -> int:\n",
    "    sum_values = 0\n",
    "    for entry in sentence_val:\n",
    "        sum_values = sum_values + sentence_val[entry]\n",
    "    average = sum_values / len(sentence_val)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Generating Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(sentences, sentence_val, threshold):\n",
    "    sentence_count = 0\n",
    "    summary = \"\"\n",
    "    for sentence in sentences:\n",
    "        if sentence[:15] in sentence_val and sentence_val[sentence[:15]] >= (threshold):\n",
    "            summary = summary + \" \" + sentence\n",
    "            sentence_count = sentence_count + 1\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call everything and get the summarization done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_matrix = create_frequency_matrix(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix = create_tf_matrix(freq_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_doc_per_words = create_document_per_words(freq_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_matrix = create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_matrix = create_tf_idf_matrix(tf_matrix, idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores = score_sentences(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = find_average_score(sentence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" story takes place universe has connection any DC come before see classic Warner movie Gritty , intimate oddly , characters live real world stakes personal Although never mentioned , story takes place past call 1981 crime rate Gotham record garbage strike has crippled city past six weeks divide `` '' `` have- '' palpable Dreams beyond , slipping delusions : HEAR sound man totally cracking : 1 INT DEPT HEALTH , - MORNING 1 CLOSE ( 30 ) , tears eyes hard control greasy , hair matted wearing , red hooded zip-up sweatshirt , threadbare gray scarf , thin years , loosely around neck NOTICE SCARS cut corners mouth forming across overworked ( 50 ) , African American cramped run-down cramped run-down building Stacks folders piled front desk , waiting fit end , before subsides takes deep breath , see -- , crazier ? Despite , real pain eyes broken like has slept certainly tense People upset , 're struggling work garbage strike like going forever tough ( ) 'bout job ? Still enjoying ? , mean , , really like think could ever work desk ( ) 2 ( CONT ) ( ) offense Writes clock , running late next ? Everyday Great bring ? ( dodging subject ) 'm sorry bring ? ( impatient ; ) Arthur , last bring ? Yes ma'am see ? reluctantly bag Pulls weathered notebook across -- 've , joke diary thoughts , observations -- tell 'm pursuing career stand-up comedy ? half-listening think 3 respond , -- Oh Because mother said , -- purpose `` bring joy world , '' ? ANGLE , pages pages notes , neat , angry-looking handwriting , cut photos hardcore pornographic magazines crude handmade drawings flash anger crosses face see picking eyebrow , obsessively stay calm eyebrow actually half-gone lot realize gives , pages gives ( loud ) `` hope death sense life '' stares back little , even though think -- mean , -- upset ? leans , -- personal know ? understand 're back holds lap 4 mom ? ? has good mostly bad big help really needs like sick lot since got home ( nods ) , good 'm was hospital , last episode -- was visit back clock , needs next , 'll see , weeks today ? nods moment stands , signal leave -- else help , Arthur ? next waiting , was wondering could doctor dosage medications ? Nothing ( record ) know ones like ? Shakes head , sleeping ? 5 ( lying ) glances file Arthur , 're seven medications must stands Zips red sweatshirt -- wan na bad anymore\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = generate_summary(sentences, sentence_scores, threshold)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
